{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c7a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e898c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep \n",
    "from selenium.webdriver.support.wait import WebDriverWait as wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfa73dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf4bda",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "761f67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DA_jobs(url):\n",
    "    url = \"https://www.naukri.com/\"\n",
    "    driver.get(url)\n",
    "    sleep(4)                            # for the web page to load properly -----> as Javascript elements takes time to load \n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    search_job.send_keys(\"Data Analyst\")\n",
    "    search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "    search_loc.send_keys(\"Bangalore\")\n",
    "#     wait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, \"//div[@class='search-btn']/button\")))\n",
    "    search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_btn.click()\n",
    "\n",
    "    job_title = []\n",
    "    company_names=[]\n",
    "    locations_list=[]\n",
    "    experience_list=[]\n",
    "  \n",
    "    sleep(4)    # for the web page to load properly\n",
    "    title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "    \n",
    "\n",
    "    \n",
    "    loc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "    company_nametag = driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a[1]\")\n",
    "    experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "\n",
    "    for i in title_tags:\n",
    "        titlename = i.text\n",
    "        \n",
    "        job_title.append(titlename)\n",
    "     \n",
    "    \n",
    "    for i in experience_tags:\n",
    "        exp = i.text\n",
    "        experience_list.append(exp)\n",
    "    \n",
    "    for i in loc_tags:\n",
    "        location = i.text\n",
    "        locations_list.append(location)\n",
    " \n",
    "    for i in company_nametag:\n",
    "        name = i.text\n",
    "        company_names.append(name)\n",
    "    \n",
    "    df=pd.DataFrame({\"Job Title\":job_title[0:10], \"Experience\":experience_list[0:10],\"Company Name\": company_names[0:10], \"Location\": locations_list[0:10]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e8cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-49341aef8049>:5: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
      "<ipython-input-4-49341aef8049>:7: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
      "<ipython-input-4-49341aef8049>:10: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
      "<ipython-input-4-49341aef8049>:19: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  title_tags = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
      "<ipython-input-4-49341aef8049>:23: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  loc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
      "<ipython-input-4-49341aef8049>:24: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  company_nametag = driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a[1]\")\n",
      "<ipython-input-4-49341aef8049>:25: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Business Data Analyst</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Tech Data Advanced Solutions India Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Flipkart Analytics</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Urgent Openings For Data Analyst / Business An...</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Rupeek Fintech Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Data Analyst(BigId) - Capco - Bangalore</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Capco Technologies Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>CINDREBAY SCHOOL OF FASHION &amp; INTERIOR DESIGN</td>\n",
       "      <td>Kochi/Cochin, Cannanore/Kannur, Nagpur, Calicu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Pioneer Business Solutions</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Advanced Computer Software</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Pioneer Business Solutions</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title Experience  \\\n",
       "0                       Senior Business Data Analyst    3-8 Yrs   \n",
       "1                  Data Analyst - Flipkart Analytics    0-3 Yrs   \n",
       "2     Business Data Analyst - Database Design/Mining    2-5 Yrs   \n",
       "3  Urgent Openings For Data Analyst / Business An...    1-6 Yrs   \n",
       "4                                       Data Analyst    0-2 Yrs   \n",
       "5   Business Data Analyst(BigId) - Capco - Bangalore    3-8 Yrs   \n",
       "6                                       Data Analyst    1-4 Yrs   \n",
       "7                                Senior Data Analyst   6-11 Yrs   \n",
       "8                                Senior Data Analyst    3-5 Yrs   \n",
       "9                                    Sr Data Analyst    3-8 Yrs   \n",
       "\n",
       "                                    Company Name  \\\n",
       "0     Tech Data Advanced Solutions India Pvt Ltd   \n",
       "1                                       Flipkart   \n",
       "2                                    AugmatrixGo   \n",
       "3                                       Flipkart   \n",
       "4                         Rupeek Fintech Pvt Ltd   \n",
       "5                     Capco Technologies Pvt Ltd   \n",
       "6  CINDREBAY SCHOOL OF FASHION & INTERIOR DESIGN   \n",
       "7                     Pioneer Business Solutions   \n",
       "8                     Advanced Computer Software   \n",
       "9                     Pioneer Business Solutions   \n",
       "\n",
       "                                            Location  \n",
       "0            Bangalore/Bengaluru, Mumbai (All Areas)  \n",
       "1                     Bangalore/Bengaluru(Bellandur)  \n",
       "2                                Bangalore/Bengaluru  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6  Kochi/Cochin, Cannanore/Kannur, Nagpur, Calicu...  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA_jobs(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103d126",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4f6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DS_jobs(url):\n",
    "\n",
    "    url = \"https://www.naukri.com/\"\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    search_job.send_keys(\"Data Scientist\")\n",
    "    search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "    search_loc.send_keys(\"Bangalore\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_btn.click()\n",
    "\n",
    "    job_title = []\n",
    "    company_names=[]\n",
    "    locations_list=[]\n",
    "    experience_list=[]\n",
    "    \n",
    "    sleep(4)\n",
    "    title_tags = driver.find_elements_by_xpath(r\"//a[@class='title fw500 ellipsis']\")\n",
    "    loc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "    company_nametag = driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a[1]\")\n",
    "    experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "\n",
    "    for i in title_tags:\n",
    "        titlename = i.text\n",
    "        job_title.append(titlename)\n",
    "    \n",
    "    for i in experience_tags:\n",
    "        exp = i.text\n",
    "        experience_list.append(exp)\n",
    "    \n",
    "    for i in loc_tags:\n",
    "        location = i.text\n",
    "        locations_list.append(location)\n",
    " \n",
    "    for i in company_nametag:\n",
    "        name = i.text\n",
    "        company_names.append(name)\n",
    "    \n",
    "   \n",
    "    \n",
    "    df=pd.DataFrame({\"Job Title\":job_title[0:10], \"Experience\":experience_list[0:10],\"Company Name\": company_names[0:10], \"Location\": locations_list[0:10]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5252454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-1ad230c28173>:6: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
      "<ipython-input-6-1ad230c28173>:8: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
      "<ipython-input-6-1ad230c28173>:10: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
      "<ipython-input-6-1ad230c28173>:19: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  title_tags = driver.find_elements_by_xpath(r\"//a[@class='title fw500 ellipsis']\")\n",
      "<ipython-input-6-1ad230c28173>:20: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  loc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
      "<ipython-input-6-1ad230c28173>:21: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  company_nametag = driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a[1]\")\n",
      "<ipython-input-6-1ad230c28173>:22: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Concentrix Daksh Services</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Toppr</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Process Innovation Analyst - APAC/Data Scienti...</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Mobiotics IT Solution Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru(HSR Layout)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bigshyft Hiring for PayTM (One97 Communications)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title Experience  \\\n",
       "0                              Senior Data Scientist    2-5 Yrs   \n",
       "1    Forecasting Analyst/ Data Scientist (US Client)    3-8 Yrs   \n",
       "2                                     Data Scientist    1-3 Yrs   \n",
       "3  Process Innovation Analyst - APAC/Data Scienti...    4-8 Yrs   \n",
       "4                                     Data Scientist    3-7 Yrs   \n",
       "5                                     Data Scientist    2-5 Yrs   \n",
       "6                                     Data Scientist   5-10 Yrs   \n",
       "7                              Senior Data Scientist    3-7 Yrs   \n",
       "8                 Data Scientist: Advanced Analytics   5-10 Yrs   \n",
       "9            Data Scientist: Artificial Intelligence    4-6 Yrs   \n",
       "\n",
       "                                       Company Name  \\\n",
       "0                                      Hitachi Ltd.   \n",
       "1                         Concentrix Daksh Services   \n",
       "2                                             Toppr   \n",
       "3                                             Bayer   \n",
       "4                                      Hitachi Ltd.   \n",
       "5                     Mobiotics IT Solution Pvt Ltd   \n",
       "6                                      Hitachi Ltd.   \n",
       "7  Bigshyft Hiring for PayTM (One97 Communications)   \n",
       "8                            IBM India Pvt. Limited   \n",
       "9                            IBM India Pvt. Limited   \n",
       "\n",
       "                                            Location  \n",
       "0                                Bangalore/Bengaluru  \n",
       "1              Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "2  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...  \n",
       "3                     Bangalore/Bengaluru, Hyderabad  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                    Bangalore/Bengaluru(HSR Layout)  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS_jobs(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1eca19",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6001792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DS_filter_jobs(url):\n",
    "\n",
    "    url = \"https://www.naukri.com/\"\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "    search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    search_job.send_keys(\"Data Scientist\")\n",
    "    search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "    search_loc.send_keys(\"Bangalore\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_btn.click()\n",
    "    sleep(4)\n",
    "    filter_loc = driver.find_element_by_xpath(\"//label[@for='chk-Delhi / NCR-cityTypeGid-']/i[1]\")\n",
    "    filter_loc.click()\n",
    "    sleep(4)\n",
    "    filter_sal = driver.find_element_by_xpath(\"//div[@class='mt-8 chckBoxCont']/label[@for='chk-3-6 Lakhs-ctcFilter-']/i\")\n",
    "    filter_sal.click()\n",
    "\n",
    "    job_title = []\n",
    "    company_names=[]\n",
    "    locations_list=[]\n",
    "    experience_list=[]\n",
    "    \n",
    "    sleep(4)\n",
    "    title_tags = driver.find_elements_by_xpath(r\"//a[@class='title fw500 ellipsis']\")\n",
    "    loc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "    company_nametag = driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a[1]\")\n",
    "    experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "\n",
    "    for i in title_tags:\n",
    "        titlename = i.text\n",
    "        job_title.append(titlename)\n",
    "    \n",
    "    for i in experience_tags:\n",
    "        exp = i.text\n",
    "        experience_list.append(exp)\n",
    "    \n",
    "    for i in loc_tags:\n",
    "        location = i.text\n",
    "        locations_list.append(location)\n",
    " \n",
    "    for i in company_nametag:\n",
    "        name = i.text\n",
    "        company_names.append(name)\n",
    "    \n",
    "   \n",
    "    \n",
    "    df=pd.DataFrame({\"Job Title\":job_title[0:10], \"Experience\":experience_list[0:10],\"Company Name\": company_names[0:10], \"Location\": locations_list[0:10]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d423ebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-951487bb7632>:6: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
      "<ipython-input-8-951487bb7632>:8: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_loc = driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
      "<ipython-input-8-951487bb7632>:10: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
      "<ipython-input-8-951487bb7632>:13: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  filter_loc = driver.find_element_by_xpath(\"//label[@for='chk-Delhi / NCR-cityTypeGid-']/i[1]\")\n",
      "<ipython-input-8-951487bb7632>:16: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  filter_sal = driver.find_element_by_xpath(\"//div[@class='mt-8 chckBoxCont']/label[@for='chk-3-6 Lakhs-ctcFilter-']/i\")\n",
      "<ipython-input-8-951487bb7632>:25: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  title_tags = driver.find_elements_by_xpath(r\"//a[@class='title fw500 ellipsis']\")\n",
      "<ipython-input-8-951487bb7632>:26: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  loc_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
      "<ipython-input-8-951487bb7632>:27: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  company_nametag = driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a[1]\")\n",
      "<ipython-input-8-951487bb7632>:28: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  experience_tags = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>ThinkBumblebee Analytics Pvt. Ltd.</td>\n",
       "      <td>Pune, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Think i</td>\n",
       "      <td>Kochi/Cochin, Kolkata, Hyderabad/Secunderabad,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Academic Counsellor - Data Scientist</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>GreatLearning</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>Gurgaon, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Immediate requirement For Data Scientist</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>CALIBEHR BUSINESS SUPPORT SERVICES PRIVATE LIM...</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>EXL Service</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Urban Company</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Hexagon Geosystems Services India P.Ltd.</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Job Title Experience  \\\n",
       "0                            Data Scientist    2-6 Yrs   \n",
       "1                            Data Scientist    0-2 Yrs   \n",
       "2                            Data Scientist    3-7 Yrs   \n",
       "3      Academic Counsellor - Data Scientist    1-4 Yrs   \n",
       "4                            Data Scientist    3-7 Yrs   \n",
       "5                            Data Scientist    1-3 Yrs   \n",
       "6  Immediate requirement For Data Scientist    2-7 Yrs   \n",
       "7                            Data Scientist    3-5 Yrs   \n",
       "8                            Data Scientist    1-3 Yrs   \n",
       "9                            Data Scientist   6-11 Yrs   \n",
       "\n",
       "                                        Company Name  \\\n",
       "0                 ThinkBumblebee Analytics Pvt. Ltd.   \n",
       "1                                            Think i   \n",
       "2                                  Fractal Analytics   \n",
       "3                                      GreatLearning   \n",
       "4                                          BlackBuck   \n",
       "5                                     Country Veggie   \n",
       "6  CALIBEHR BUSINESS SUPPORT SERVICES PRIVATE LIM...   \n",
       "7                                        EXL Service   \n",
       "8                                      Urban Company   \n",
       "9           Hexagon Geosystems Services India P.Ltd.   \n",
       "\n",
       "                                            Location  \n",
       "0             Pune, Bangalore/Bengaluru, Delhi / NCR  \n",
       "1  Kochi/Cochin, Kolkata, Hyderabad/Secunderabad,...  \n",
       "2      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "3              Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "4                                 Gurgaon, Bengaluru  \n",
       "5  Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...  \n",
       "6  Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...  \n",
       "7              Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "8              Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "9              Gurgaon/Gurugram, Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS_filter_jobs(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac99183",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9f0a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-ce37d4335094>:5: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  click_oncross = driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button[1]\")   #comment this if running the same chrome window since 1st question\n",
      "<ipython-input-11-ce37d4335094>:8: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_prod = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input[1]\")\n",
      "<ipython-input-11-ce37d4335094>:10: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
      "<ipython-input-11-ce37d4335094>:21: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  prodname = driver.find_elements_by_xpath(\"//div[@class='_1xHGtK _373qXS']/div[@class='_2B099V']/div[1]\")\n",
      "<ipython-input-11-ce37d4335094>:25: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  price_tag= driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
      "<ipython-input-11-ce37d4335094>:29: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  descr_tags=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")\n",
      "<ipython-input-11-ce37d4335094>:33: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  disc_tags= driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
      "<ipython-input-11-ce37d4335094>:38: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  next_btn = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']/span\")[0]\n",
      "<ipython-input-11-ce37d4335094>:41: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  next_btn = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")[1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹250</td>\n",
       "      <td>84% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹349</td>\n",
       "      <td>88% off</td>\n",
       "      <td>UV Protection Rectangular, Over-sized Sunglass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹188</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>₹276</td>\n",
       "      <td>83% off</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Round Sungl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹330</td>\n",
       "      <td>73% off</td>\n",
       "      <td>UV Protection Sports Sunglasses (73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹349</td>\n",
       "      <td>82% off</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>₹196</td>\n",
       "      <td>80% off</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (53)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹224</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (53)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Price Discount  \\\n",
       "0           PIRASO  ₹250  84% off   \n",
       "1           PIRASO  ₹349  88% off   \n",
       "2             SRPM  ₹188  85% off   \n",
       "3           SUNBEE  ₹276  83% off   \n",
       "4         Fastrack  ₹639  20% off   \n",
       "..             ...   ...      ...   \n",
       "95  ROZZETTA CRAFT  ₹330  73% off   \n",
       "96       ROYAL SON  ₹349  82% off   \n",
       "97          GANSTA  ₹449  70% off   \n",
       "98          GANSTA  ₹196  80% off   \n",
       "99       ROYAL SON  ₹224  85% off   \n",
       "\n",
       "                                          Description  \n",
       "0               UV Protection Aviator Sunglasses (55)  \n",
       "1   UV Protection Rectangular, Over-sized Sunglass...  \n",
       "2              UV Protection Wayfarer Sunglasses (56)  \n",
       "3   UV Protection, Polarized, Mirrored Round Sungl...  \n",
       "4    UV Protection Rectangular Sunglasses (Free Size)  \n",
       "..                                                ...  \n",
       "95               UV Protection Sports Sunglasses (73)  \n",
       "96  UV Protection, Gradient Retro Square Sunglasse...  \n",
       "97   UV Protection Rectangular Sunglasses (Free Size)  \n",
       "98   UV Protection, Mirrored Wayfarer Sunglasses (53)  \n",
       "99           UV Protection Clubmaster Sunglasses (53)  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flipkart(url):\n",
    "    url = \"https://www.flipkart.com/\"\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "    click_oncross = driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button[1]\")   #comment this if running the same chrome window since 1st question\n",
    "    click_oncross.click()                                                               #comment this if running the same chrome window since 1st question\n",
    "    \n",
    "    search_prod = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input[1]\")\n",
    "    search_prod.send_keys(\"Sunglasses\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    search_btn.click()\n",
    "    sleep(4)\n",
    "    \n",
    "    discount=[]\n",
    "    name = []\n",
    "    price = []\n",
    "    descr=[]\n",
    "            \n",
    "    for page in range(1,4):\n",
    "        \n",
    "        prodname = driver.find_elements_by_xpath(\"//div[@class='_1xHGtK _373qXS']/div[@class='_2B099V']/div[1]\")\n",
    "        for i in prodname:\n",
    "            name.append(i.text)\n",
    "\n",
    "        price_tag= driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "        for i in price_tag[0:40]:\n",
    "            price.append(i.text)\n",
    "\n",
    "        descr_tags=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")\n",
    "        for i in descr_tags:\n",
    "            descr.append(i.text)\n",
    "\n",
    "        disc_tags= driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "        for i in disc_tags[0:40]:\n",
    "            discount.append(i.text)\n",
    "        \n",
    "        if page==1:\n",
    "            next_btn = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']/span\")[0]\n",
    "           \n",
    "        else:\n",
    "            next_btn = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")[1]\n",
    "        next_btn.click()\n",
    "        sleep(4)\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame({\"Name\": name[0:100], \"Price\": price[0:100], \"Discount\": discount[0:100], \"Description\": descr[0:100]})\n",
    "    return df\n",
    "flipkart(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae87d29",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/\n",
    "p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage .\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4faeeb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iphone_review(url):\n",
    "    url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\"\n",
    "    driver.get(url)\n",
    "\n",
    "    sleep(4)\n",
    "    all_btn = driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "    all_btn.click()\n",
    "\n",
    "    sleep(4)\n",
    "    ratings=[]\n",
    "    review_sum=[]\n",
    "    descr=[]\n",
    "\n",
    "    for page in range(1,11):\n",
    "\n",
    "        review_title=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "        for i in review_title:\n",
    "            review_sum.append(i.text) \n",
    "\n",
    "        rating_tags=driver.find_elements_by_xpath(\"//div[@class='_27M-vq']/div[1]/div[1]/div[1]\")\n",
    "        for i in rating_tags:\n",
    "            ratings.append(i.text[0])\n",
    "\n",
    "        descr_tags=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "        for i in descr_tags:\n",
    "            descr.append(i.text)\n",
    "\n",
    "        if page==1:\n",
    "            driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "        else:\n",
    "            driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")[1].click()\n",
    "\n",
    "#         print(len(review_sum),len(ratings), len(descr))\n",
    "        sleep(2)\n",
    "    df = pd.DataFrame({\"Short review\": review_sum, \"Rating\": ratings, \"Full review\": descr})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7d4c7c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-dd1a693bfc8d>:6: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  all_btn = driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")\n",
      "<ipython-input-12-dd1a693bfc8d>:16: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  review_title=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
      "<ipython-input-12-dd1a693bfc8d>:20: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  rating_tags=driver.find_elements_by_xpath(\"//div[@class='_27M-vq']/div[1]/div[1]/div[1]\")\n",
      "<ipython-input-12-dd1a693bfc8d>:24: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  descr_tags=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
      "<ipython-input-12-dd1a693bfc8d>:29: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
      "<ipython-input-12-dd1a693bfc8d>:31: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")[1].click()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Short review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>5</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>5</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>5</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>5</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Super!</td>\n",
       "      <td>5</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Just wow!</td>\n",
       "      <td>5</td>\n",
       "      <td>The ultimate performance\\nCamera is superb\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>5</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Awesome</td>\n",
       "      <td>5</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Decent product</td>\n",
       "      <td>3</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Short review Rating  \\\n",
       "0           Brilliant      5   \n",
       "1      Simply awesome      5   \n",
       "2    Perfect product!      5   \n",
       "3   Worth every penny      5   \n",
       "4           Fabulous!      5   \n",
       "..                ...    ...   \n",
       "95             Super!      5   \n",
       "96          Just wow!      5   \n",
       "97  Terrific purchase      5   \n",
       "98            Awesome      5   \n",
       "99     Decent product      3   \n",
       "\n",
       "                                          Full review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "96  The ultimate performance\\nCamera is superb\\nTh...  \n",
       "97  I use a Note10+ and have been using both iOS a...  \n",
       "98  The phone is completely good\\nAs far as camera...  \n",
       "99  Everything u ll like it when u use this iPhone...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_review(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0158f",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a51ba3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-e554353c17b0>:7: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  click_oncross = driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button[1]\")\n",
      "<ipython-input-14-e554353c17b0>:13: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_prod = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input[1]\")\n",
      "<ipython-input-14-e554353c17b0>:15: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
      "<ipython-input-14-e554353c17b0>:26: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  prodname = driver.find_elements_by_xpath(\"//div[@class='_1xHGtK _373qXS']/div[@class='_2B099V']/div[1]\")\n",
      "<ipython-input-14-e554353c17b0>:30: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  price_tag= driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
      "<ipython-input-14-e554353c17b0>:34: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  descr_tags=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")\n",
      "<ipython-input-14-e554353c17b0>:38: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  disc_tags= driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
      "<ipython-input-14-e554353c17b0>:43: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  next_btn = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']/span\")[0]\n",
      "<ipython-input-14-e554353c17b0>:46: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  next_btn = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")[1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>₹599</td>\n",
       "      <td>60% off</td>\n",
       "      <td>Unique &amp; Perfect Collection Combo Pack of 02 S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>₹7,649</td>\n",
       "      <td>15% off</td>\n",
       "      <td>BMW MMS Speedcat M Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>₹479</td>\n",
       "      <td>63% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RODDICK SHOES</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "      <td>Smart Casuals Canvas Shoes Combo pack of 2 Sne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ASIAN</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "      <td>Fashion Outdoor Canvas Casual Light Weight Lac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>₹399</td>\n",
       "      <td>50% off</td>\n",
       "      <td>Skypy-31 Walking Shoes,Training Shoes,Sneakers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Neeman's</td>\n",
       "      <td>₹347</td>\n",
       "      <td>56% off</td>\n",
       "      <td>516 Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>₹2,399</td>\n",
       "      <td>20% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name   Price Discount  \\\n",
       "0          Chevit    ₹599  60% off   \n",
       "1            PUMA  ₹7,649  15% off   \n",
       "2         Numenzo    ₹479  63% off   \n",
       "3       SCATCHITE    ₹398  60% off   \n",
       "4        Magnolia    ₹398  60% off   \n",
       "..            ...     ...      ...   \n",
       "95  RODDICK SHOES    ₹399  60% off   \n",
       "96          ASIAN    ₹474  52% off   \n",
       "97         Chevit    ₹399  50% off   \n",
       "98       Neeman's    ₹347  56% off   \n",
       "99          BIRDE  ₹2,399  20% off   \n",
       "\n",
       "                                          Description  \n",
       "0   Unique & Perfect Collection Combo Pack of 02 S...  \n",
       "1                 BMW MMS Speedcat M Sneakers For Men  \n",
       "2                                    Sneakers For Men  \n",
       "3                           Sneakers Sneakers For Men  \n",
       "4                                    Sneakers For Men  \n",
       "..                                                ...  \n",
       "95  Smart Casuals Canvas Shoes Combo pack of 2 Sne...  \n",
       "96  Fashion Outdoor Canvas Casual Light Weight Lac...  \n",
       "97  Skypy-31 Walking Shoes,Training Shoes,Sneakers...  \n",
       "98                               516 Sneakers For Men  \n",
       "99                                   Sneakers For Men  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sneakers(url):\n",
    "    url = \"https://www.flipkart.com/\"\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "    \n",
    "    try:\n",
    "        click_oncross = driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button[1]\")   \n",
    "        click_oncross.click()                                                               \n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    search_prod = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input[1]\")\n",
    "    search_prod.send_keys(\"Sneakers\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    search_btn.click()\n",
    "    sleep(4)\n",
    "\n",
    "    discount=[]\n",
    "    name = []\n",
    "    price = []\n",
    "    descr=[]\n",
    "            \n",
    "    for page in range(1,4):\n",
    "        \n",
    "        prodname = driver.find_elements_by_xpath(\"//div[@class='_1xHGtK _373qXS']/div[@class='_2B099V']/div[1]\")\n",
    "        for i in prodname:\n",
    "            name.append(i.text)\n",
    "\n",
    "        price_tag= driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "        for i in price_tag[0:40]:\n",
    "            price.append(i.text)\n",
    "\n",
    "        descr_tags=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")\n",
    "        for i in descr_tags:\n",
    "            descr.append(i.text)\n",
    "\n",
    "        disc_tags= driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "        for i in disc_tags[0:40]:\n",
    "            discount.append(i.text)\n",
    "        \n",
    "        if page==1:\n",
    "            next_btn = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']/span\")[0]\n",
    "           \n",
    "        else:\n",
    "            next_btn = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")[1]\n",
    "        next_btn.click()\n",
    "        sleep(4)\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame({\"Name\": name[0:100], \"Price\": price[0:100], \"Discount\": discount[0:100], \"Description\": descr[0:100]})\n",
    "    return df\n",
    "sneakers(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336349c",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image. And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a10e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myntra_shoes(url):\n",
    "\n",
    "    url = \"https://www.myntra.com/shoes/\"\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "    \n",
    "    filter_col = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "    filter_col.click()\n",
    "    sleep(4)\n",
    "    filter_price = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "    filter_price.click()\n",
    "\n",
    "\n",
    "    sleep(4)\n",
    "    name = []\n",
    "    price = []\n",
    "    descr=[]\n",
    "\n",
    "    for page in range(1,3):\n",
    "\n",
    "        prodname = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")\n",
    "        for i in prodname:\n",
    "            name.append(i.text)\n",
    "\n",
    "        price_tag = driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]\")\n",
    "        for i in price_tag:\n",
    "            price.append(i.text)\n",
    "\n",
    "        descr_tags=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\")\n",
    "        for i in descr_tags:\n",
    "            descr.append(i.text)\n",
    "\n",
    "\n",
    "        next_btn = driver.find_element_by_xpath(\"//li[@class='pagination-next']/a[1]\")\n",
    "        next_btn.click()\n",
    "        sleep(4)\n",
    "#         print(len(name),len(price), len(descr))\n",
    "    \n",
    "    df=pd.DataFrame({\"Name\":name, \"Price\":price ,\"Description\": descr[0:200:2]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1527566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-17ec094cc4eb>:7: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  filter_col = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
      "<ipython-input-15-17ec094cc4eb>:10: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  filter_price = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
      "<ipython-input-15-17ec094cc4eb>:21: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  prodname = driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")\n",
      "<ipython-input-15-17ec094cc4eb>:25: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  price_tag = driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]\")\n",
      "<ipython-input-15-17ec094cc4eb>:29: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  descr_tags=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\")\n",
      "<ipython-input-15-17ec094cc4eb>:34: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  next_btn = driver.find_element_by_xpath(\"//li[@class='pagination-next']/a[1]\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 7195</td>\n",
       "      <td>Men Zoom Span 4 Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 7995</td>\n",
       "      <td>Men FLIGHT LEGACY Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Rs. 8099Rs. 8999</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calvin Klein</td>\n",
       "      <td>Rs. 8249Rs. 10999</td>\n",
       "      <td>Men Mid-Top Runner Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 7195</td>\n",
       "      <td>Men BlazerLow '77 Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>KLEAT</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Men Solid Brogues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Rs. 8999</td>\n",
       "      <td>Women Quilted Leather Pumps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Rs. 9500</td>\n",
       "      <td>Women Heeled Boots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name              Price                        Description\n",
       "0           Nike           Rs. 7195      Men Zoom Span 4 Running Shoes\n",
       "1           Nike           Rs. 7995         Men FLIGHT LEGACY Sneakers\n",
       "2   Hush Puppies   Rs. 8099Rs. 8999  Men Solid Leather Formal Slip-Ons\n",
       "3   Calvin Klein  Rs. 8249Rs. 10999        Men Mid-Top Runner Sneakers\n",
       "4           Nike           Rs. 7195         Men BlazerLow '77 Sneakers\n",
       "..           ...                ...                                ...\n",
       "95          Geox           Rs. 9999                Women Leather Pumps\n",
       "96       Bugatti           Rs. 9999                  Men Running Shoes\n",
       "97         KLEAT           Rs. 7999                  Men Solid Brogues\n",
       "98          Geox           Rs. 8999        Women Quilted Leather Pumps\n",
       "99       Saint G           Rs. 9500                 Women Heeled Boots\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myntra_shoes(\"https://www.myntra.com/shoes/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b716f6",
   "metadata": {},
   "source": [
    "Q8. Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1798bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon_laptop(url):\n",
    "    url = \"https://www.amazon.in/\"\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "\n",
    "    search_prod = driver.find_element_by_xpath(\"//div[@class='nav-search-field ']/input[1]\")\n",
    "    search_prod.send_keys(\"Laptop\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//span[@id='nav-search-submit-text']/input[1]\")\n",
    "    search_btn.click()\n",
    "    sleep(4)\n",
    "\n",
    "    # filter_i9 = driver.find_element_by_xpath(\"//li[@id='p_n_feature_thirteen_browse-bin/16757432031']/span[1]/a[1]/div[1]/label[1]/i[1]\")\n",
    "    # filter_i9.click()\n",
    "    # # sleep(4)\n",
    "    filter_i7 = driver.find_element_by_xpath(\"//span[text()='Intel Core i7']\")\n",
    "    filter_i7.click()\n",
    "\n",
    "    prodname=[]\n",
    "    names=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a/span[1]\") \n",
    "    for i in names:\n",
    "        prodname.append(i.text)\n",
    "    ratings=[]\n",
    "    stars = driver.find_elements_by_xpath(\"//div[@class='a-row a-size-small']/span[1]\")\n",
    "    for i in stars:\n",
    "        ratings.append(i.get_attribute('aria-label'))\n",
    "\n",
    "    ratings.insert(8, \"Not Available\" )\n",
    "\n",
    "    price=[]\n",
    "    price_tag=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "    for i in price_tag:\n",
    "        price.append(i.text)\n",
    "    df=pd.DataFrame({\"Product Name & Descr.\": prodname[0:10], \"Ratings\": ratings[0:10], \"Price\":price[0:10]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cc8a4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-d90ede4e7a20>:6: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_prod = driver.find_element_by_xpath(\"//div[@class='nav-search-field ']/input[1]\")\n",
      "<ipython-input-17-d90ede4e7a20>:8: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//span[@id='nav-search-submit-text']/input[1]\")\n",
      "<ipython-input-17-d90ede4e7a20>:15: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  filter_i7 = driver.find_element_by_xpath(\"//span[text()='Intel Core i7']\")\n",
      "<ipython-input-17-d90ede4e7a20>:19: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  names=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a/span[1]\")\n",
      "<ipython-input-17-d90ede4e7a20>:23: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  stars = driver.find_elements_by_xpath(\"//div[@class='a-row a-size-small']/span[1]\")\n",
      "<ipython-input-17-d90ede4e7a20>:30: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  price_tag=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name &amp; Descr.</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Envy Intel 11th Gen Core i7 Processor 13.3 ...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>1,24,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>56,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>1,13,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Microsoft Surface Laptop Studio - 14.4\" Touchs...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>3,73,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>88,508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>93,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 13...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>89,700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Product Name & Descr.             Ratings  \\\n",
       "0  Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...  4.3 out of 5 stars   \n",
       "1  HP Envy Intel 11th Gen Core i7 Processor 13.3 ...  4.1 out of 5 stars   \n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.2 out of 5 stars   \n",
       "3  ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...  4.7 out of 5 stars   \n",
       "4  Microsoft Surface Laptop Studio - 14.4\" Touchs...  4.0 out of 5 stars   \n",
       "5  HP Pavilion (2021) Intel 11th Gen Core i7 14 i...  4.3 out of 5 stars   \n",
       "6  Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...  4.6 out of 5 stars   \n",
       "7  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  4.1 out of 5 stars   \n",
       "8  Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...       Not Available   \n",
       "9  HP Pavilion 13(2021) 11th Gen Intel Core i7 13...  3.8 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0    89,990  \n",
       "1  1,24,000  \n",
       "2    56,990  \n",
       "3  1,13,990  \n",
       "4  3,73,999  \n",
       "5    84,990  \n",
       "6    88,508  \n",
       "7    85,990  \n",
       "8    93,990  \n",
       "9    89,700  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_laptop(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9086f26",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "\n",
    "This task will be done in following steps:\n",
    "\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de6492fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ambbox_jobs(url):\n",
    "    url = \"https://www.ambitionbox.com/\"\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "\n",
    "\n",
    "    click_jobs = driver.find_element_by_xpath(\"//a[@class='link jobs']\")\n",
    "    click_jobs.click()\n",
    "    enter_job_title = driver.find_element_by_xpath(\"//input[@class='input tt-input']\")\n",
    "    enter_job_title.send_keys(\"Data Scientist\")\n",
    "    search_btn = driver.find_element_by_xpath(\"//button[@class='ab_btn search-btn round']/span[1]\")\n",
    "    search_btn.click()\n",
    "    sleep(4)\n",
    "\n",
    "    drop_down = driver.find_element_by_xpath(\"//div[@title='Location']/i[1]\")\n",
    "    drop_down.click()\n",
    "    sleep(2)\n",
    "\n",
    "    enter_loc = driver.find_element_by_xpath(\"//input[@placeholder='Search locations']\")\n",
    "    enter_loc.send_keys(\"Noida\")\n",
    "\n",
    "    location = driver.find_element_by_xpath(\"//input[@id='location_Noida']\")\n",
    "    location.click()\n",
    "    sleep(4)\n",
    "\n",
    "    jobtitle=[]\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='title noclick']\"):\n",
    "        jobtitle.append(i.text)\n",
    "\n",
    "    compname=[]\n",
    "    for i in driver.find_elements_by_xpath(\"//p[@class='company body-medium']\"):\n",
    "        compname.append(i.text)\n",
    "        \n",
    "    exp=[]\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='other-info']/div[1]/div[1]\"):\n",
    "        exp.append(i.text)\n",
    "        \n",
    "    df=pd.DataFrame({\"Job title\": jobtitle, \"Name\": compname, \"Experience\":exp})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f55c3be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-af90fa018b67>:7: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  click_jobs = driver.find_element_by_xpath(\"//a[@class='link jobs']\")\n",
      "<ipython-input-19-af90fa018b67>:9: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  enter_job_title = driver.find_element_by_xpath(\"//input[@class='input tt-input']\")\n",
      "<ipython-input-19-af90fa018b67>:11: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_btn = driver.find_element_by_xpath(\"//button[@class='ab_btn search-btn round']/span[1]\")\n",
      "<ipython-input-19-af90fa018b67>:15: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  drop_down = driver.find_element_by_xpath(\"//div[@title='Location']/i[1]\")\n",
      "<ipython-input-19-af90fa018b67>:19: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  enter_loc = driver.find_element_by_xpath(\"//input[@placeholder='Search locations']\")\n",
      "<ipython-input-19-af90fa018b67>:22: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  location = driver.find_element_by_xpath(\"//input[@id='location_Noida']\")\n",
      "<ipython-input-19-af90fa018b67>:27: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//a[@class='title noclick']\"):\n",
      "<ipython-input-19-af90fa018b67>:31: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//p[@class='company body-medium']\"):\n",
      "<ipython-input-19-af90fa018b67>:35: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//div[@class='other-info']/div[1]/div[1]\"):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urgent Requirement || Data Scientist || Noida</td>\n",
       "      <td>Steria India Ltd</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Group Lead-Data Scientist</td>\n",
       "      <td>Ameriprise Financial</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jubilant FoodWorks - Data Scientist - Deep Lea...</td>\n",
       "      <td>Jubilant Foodworks Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Urgent Vacancy || Data Scientist || Noida</td>\n",
       "      <td>Steria India Ltd</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Urgent Requirement || Data Scientist || Noida</td>\n",
       "      <td>Steria India Ltd</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>HCL Technologies Limited</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Manager - Data Scientist - Retail/BFSI (8-15 yrs)</td>\n",
       "      <td>GI Group</td>\n",
       "      <td>8-15 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Machine Learning (5-14 yrs)</td>\n",
       "      <td>Zyoin</td>\n",
       "      <td>5-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Data Science/Model Developmen...</td>\n",
       "      <td>GI Group</td>\n",
       "      <td>0-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job title  \\\n",
       "0                                     Data Scientist   \n",
       "1      Urgent Requirement || Data Scientist || Noida   \n",
       "2                          Group Lead-Data Scientist   \n",
       "3  Jubilant FoodWorks - Data Scientist - Deep Lea...   \n",
       "4          Urgent Vacancy || Data Scientist || Noida   \n",
       "5      Urgent Requirement || Data Scientist || Noida   \n",
       "6                              Senior Data Scientist   \n",
       "7  Manager - Data Scientist - Retail/BFSI (8-15 yrs)   \n",
       "8       Data Scientist - Machine Learning (5-14 yrs)   \n",
       "9  Data Scientist - Data Science/Model Developmen...   \n",
       "\n",
       "                                             Name Experience  \n",
       "0  Optum Global Solutions (India) Private Limited    2-6 Yrs  \n",
       "1                                Steria India Ltd    4-8 Yrs  \n",
       "2                            Ameriprise Financial    4-7 Yrs  \n",
       "3                      Jubilant Foodworks Limited    2-6 Yrs  \n",
       "4                                Steria India Ltd    2-6 Yrs  \n",
       "5                                Steria India Ltd    4-8 Yrs  \n",
       "6                        HCL Technologies Limited  10-15 Yrs  \n",
       "7                                        GI Group   8-15 Yrs  \n",
       "8                                           Zyoin   5-14 Yrs  \n",
       "9                                        GI Group    0-6 Yrs  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambbox_jobs(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f0d0a",
   "metadata": {},
   "source": [
    "Q10: You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83ea5175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ambbox_sal(url):\n",
    "    url = \"https://www.ambitionbox.com/\"\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "\n",
    "\n",
    "    click_sal = driver.find_element_by_xpath(\"//a[@class='link salaries']\")\n",
    "    click_sal.click()\n",
    "    enter_job = driver.find_element_by_xpath(\"//input[@class='component-input tt-input']\")\n",
    "    enter_job.send_keys(\"Data Scientist\")\n",
    "    searchbtn = driver.find_element_by_xpath(\"//button[@class='ab_btn search-btn round component-search-btn']\")\n",
    "    searchbtn.click()\n",
    "    sleep(4)\n",
    "\n",
    "    click_ds_sal = driver.find_element_by_xpath(\"//a[@data-ctorig='https://www.ambitionbox.com/profile/data-scientist-salary']\")\n",
    "    click_ds_sal.click()\n",
    "    sleep(4)\n",
    "\n",
    "    driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "    totalsal=[]\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='company-info']/div[1]/span[1]\"):\n",
    "        totalsal.append(i.text)\n",
    "\n",
    "    compname=[]\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='company-info']/div[1]/a[1]\"):\n",
    "        compname.append(i.text)\n",
    "\n",
    "    exp=[]\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='salaries one-line sbold-list-header']/span[1]\"):\n",
    "        exp.append(i.text)\n",
    "\n",
    "    minsal=[]\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='result-col salary-range']/div[1]/div[2]/div[1]\"):\n",
    "        minsal.append(i.text)\n",
    "\n",
    "    maxsal=[]\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='result-col salary-range']/div[1]/div[2]/div[2]\"):\n",
    "        maxsal.append(i.text)\n",
    "\n",
    "    avgsal=[]\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='result-col salary-range']/div[1]/div[1]/div[1]/p\"):\n",
    "        avgsal.append(i.text)\n",
    "    \n",
    "    df = pd.DataFrame({\"Name of company\":compname, \"Experience\": exp, \"Total salaries given\": totalsal, \"Min Salary\": minsal, \"Max Salary\": maxsal, \"Average Salary\": avgsal})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7772d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-abd2e1608840>:7: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  click_sal = driver.find_element_by_xpath(\"//a[@class='link salaries']\")\n",
      "<ipython-input-28-abd2e1608840>:9: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  enter_job = driver.find_element_by_xpath(\"//input[@class='component-input tt-input']\")\n",
      "<ipython-input-28-abd2e1608840>:11: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  searchbtn = driver.find_element_by_xpath(\"//button[@class='ab_btn search-btn round component-search-btn']\")\n",
      "<ipython-input-28-abd2e1608840>:15: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  click_ds_sal = driver.find_element_by_xpath(\"//a[@data-ctorig='https://www.ambitionbox.com/profile/data-scientist-salary']\")\n",
      "<ipython-input-28-abd2e1608840>:22: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//div[@class='company-info']/div[1]/span[1]\"):\n",
      "<ipython-input-28-abd2e1608840>:26: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//div[@class='company-info']/div[1]/a[1]\"):\n",
      "<ipython-input-28-abd2e1608840>:30: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//div[@class='salaries one-line sbold-list-header']/span[1]\"):\n",
      "<ipython-input-28-abd2e1608840>:34: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//div[@class='result-col salary-range']/div[1]/div[2]/div[1]\"):\n",
      "<ipython-input-28-abd2e1608840>:38: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//div[@class='result-col salary-range']/div[1]/div[2]/div[2]\"):\n",
      "<ipython-input-28-abd2e1608840>:42: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//div[@class='result-col salary-range']/div[1]/div[1]/div[1]/p\"):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Total salaries given</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>Average Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCS</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "      <td>(594 Salaries)</td>\n",
       "      <td>₹ 4.4L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 7.3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "      <td>(355 Salaries)</td>\n",
       "      <td>₹ 5.4L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>₹ 11.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>2-12 yrs exp</td>\n",
       "      <td>(289 Salaries)</td>\n",
       "      <td>₹ 5.0L</td>\n",
       "      <td>₹ 22.5L</td>\n",
       "      <td>₹ 11.6L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cognizant</td>\n",
       "      <td>2-11 yrs exp</td>\n",
       "      <td>(233 Salaries)</td>\n",
       "      <td>₹ 4.9L</td>\n",
       "      <td>₹ 17.0L</td>\n",
       "      <td>₹ 9.4L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capgemini</td>\n",
       "      <td>2-8 yrs exp</td>\n",
       "      <td>(220 Salaries)</td>\n",
       "      <td>₹ 4.6L</td>\n",
       "      <td>₹ 14.3L</td>\n",
       "      <td>₹ 8.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>2-13 yrs exp</td>\n",
       "      <td>(182 Salaries)</td>\n",
       "      <td>₹ 4.2L</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>₹ 7.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>2-8 yrs exp</td>\n",
       "      <td>(166 Salaries)</td>\n",
       "      <td>₹ 4.5L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 8.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "      <td>(164 Salaries)</td>\n",
       "      <td>₹ 4.3L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>₹ 9.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>2-12 yrs exp</td>\n",
       "      <td>(123 Salaries)</td>\n",
       "      <td>₹ 5.0L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 12.9L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>2-10 yrs exp</td>\n",
       "      <td>(116 Salaries)</td>\n",
       "      <td>₹ 4.5L</td>\n",
       "      <td>₹ 19.0L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name of company    Experience Total salaries given Min Salary Max Salary  \\\n",
       "0               TCS   2-9 yrs exp       (594 Salaries)     ₹ 4.4L    ₹ 15.0L   \n",
       "1         Accenture   2-9 yrs exp       (355 Salaries)     ₹ 5.4L    ₹ 22.0L   \n",
       "2               IBM  2-12 yrs exp       (289 Salaries)     ₹ 5.0L    ₹ 22.5L   \n",
       "3         Cognizant  2-11 yrs exp       (233 Salaries)     ₹ 4.9L    ₹ 17.0L   \n",
       "4         Capgemini   2-8 yrs exp       (220 Salaries)     ₹ 4.6L    ₹ 14.3L   \n",
       "5     Tech Mahindra  2-13 yrs exp       (182 Salaries)     ₹ 4.2L    ₹ 16.4L   \n",
       "6           Infosys   2-8 yrs exp       (166 Salaries)     ₹ 4.5L    ₹ 25.0L   \n",
       "7             Wipro   2-9 yrs exp       (164 Salaries)     ₹ 4.3L    ₹ 18.0L   \n",
       "8          Ericsson  2-12 yrs exp       (123 Salaries)     ₹ 5.0L    ₹ 25.0L   \n",
       "9  HCL Technologies  2-10 yrs exp       (116 Salaries)     ₹ 4.5L    ₹ 19.0L   \n",
       "\n",
       "  Average Salary  \n",
       "0         ₹ 7.3L  \n",
       "1        ₹ 11.7L  \n",
       "2        ₹ 11.6L  \n",
       "3         ₹ 9.4L  \n",
       "4         ₹ 8.2L  \n",
       "5         ₹ 7.7L  \n",
       "6         ₹ 8.7L  \n",
       "7         ₹ 9.2L  \n",
       "8        ₹ 12.9L  \n",
       "9         ₹ 9.0L  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambbox_sal(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242b26d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
